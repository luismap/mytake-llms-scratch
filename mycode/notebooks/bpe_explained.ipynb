{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13e876e",
   "metadata": {},
   "source": [
    "# testing how bpe encoding could work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9bc12c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-28 11:58:28,336 - llms - INFO - hello\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import yaml\n",
    "import logging.config\n",
    "\n",
    "with open(\"logging.yaml\", \"rt\") as f:\n",
    "    config = yaml.safe_load(f.read())\n",
    "    logging.config.dictConfig(config)\n",
    "\n",
    "logger = logging.getLogger(\"llms\")\n",
    "#logger.setLevel(logging.INFO)\n",
    "logger.info(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379b9b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, deque\n",
    "\n",
    "class MyBpe:\n",
    "    def __init__(self):\n",
    "        # Maps token_id to token_str (e.g., {11246: \"some\"})\n",
    "        self.vocab = {}\n",
    "        # Maps token_str to token_id (e.g., {\"some\": 11246})\n",
    "        self.inverse_vocab = {}\n",
    "        # Dictionary of BPE merges: {(token_id1, token_id2): merged_token_id}\n",
    "        self.bpe_merges = {}\n",
    "\n",
    "        # For the official OpenAI GPT-2 merges, use a rank dict:\n",
    "        #  of form {(string_A, string_B): rank}, where lower rank = higher priority\n",
    "        self.bpe_ranks = {}\n",
    "\n",
    "    def train(self, text, vocab_size, allowed_special={\"<|endoftext|>\"}):\n",
    "        processed_text = []\n",
    "        for i, char in enumerate(text):\n",
    "            if char == \" \" and i != 0:\n",
    "                processed_text.append(\"G\")\n",
    "            if char != \" \":\n",
    "                processed_text.append(char)\n",
    "        processed_text = \"\".join(processed_text)\n",
    "    \n",
    "        print(f\"processed_text: {processed_text}\")\n",
    "\n",
    "        unique_chars = [chr(i) for i in range(256)]\n",
    "\n",
    "        unique_chars.extend(\n",
    "            char for char in sorted(set(processed_text))\n",
    "            if char not in unique_chars\n",
    "        )\n",
    "        if \"Ġ\" not in unique_chars:\n",
    "            unique_chars.append(\"Ġ\")\n",
    "\n",
    "        self.vocab = {i: char for i, char in enumerate(unique_chars)}\n",
    "        self.inverse_vocab = {char: i for i, char in self.vocab.items()}\n",
    "\n",
    "        print(f\"vocab: {list(self.vocab.items())[:3]}\")\n",
    "        print(f\"inverse_vocab: {list(self.inverse_vocab.items())[:3]}\")\n",
    "\n",
    "        token_ids = [self.inverse_vocab[char] for char in processed_text]\n",
    "\n",
    "        print(f\"token_ids: {token_ids}\")\n",
    "        print(f\"decoded tokens: {[self.vocab[idx] for idx in token_ids]}\")\n",
    "\n",
    "        # BPE steps 1-3: Repeatedly find and replace frequent pairs\n",
    "        for new_id in range(len(self.vocab), vocab_size):\n",
    "            pair_id = self.find_freq_pair(token_ids, mode=\"most\")\n",
    "            print(f\"pair_ids: {pair_id}\")\n",
    "            if pair_id is None:\n",
    "                break\n",
    "            token_ids = self.replace_pair(token_ids, pair_id, new_id)\n",
    "            self.bpe_merges[pair_id] = new_id\n",
    "\n",
    "    @staticmethod\n",
    "    def find_freq_pair(token_ids, mode=\"most\"):\n",
    "        pairs = Counter(zip(token_ids, token_ids[1:]))\n",
    "        print(f\"pairs: {pairs}\")\n",
    "        if not pairs:\n",
    "            return None\n",
    "\n",
    "        if mode == \"most\":\n",
    "            return max(pairs.items(), key=lambda x: x[1])[0]\n",
    "        elif mode == \"least\":\n",
    "            return min(pairs.items(), key=lambda x: x[1])[0]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode. Choose 'most' or 'least'.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def replace_pair(token_ids, pair_id, new_id):\n",
    "        dq = deque(token_ids)\n",
    "        replaced = []\n",
    "\n",
    "        while dq:\n",
    "            current = dq.popleft()\n",
    "            if dq and (current, dq[0]) == pair_id:\n",
    "                replaced.append(new_id)\n",
    "                # Remove the 2nd token of the pair, 1st was already removed\n",
    "                dq.popleft()\n",
    "            else:\n",
    "                replaced.append(current)\n",
    "\n",
    "        return replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1db5f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_text: theGfoxGjumpedGoverGtheGfenced\n",
      "vocab: [(0, '\\x00'), (1, '\\x01'), (2, '\\x02')]\n",
      "inverse_vocab: [('\\x00', 0), ('\\x01', 1), ('\\x02', 2)]\n",
      "token_ids: [116, 104, 101, 71, 102, 111, 120, 71, 106, 117, 109, 112, 101, 100, 71, 111, 118, 101, 114, 71, 116, 104, 101, 71, 102, 101, 110, 99, 101, 100]\n",
      "decoded tokens: ['t', 'h', 'e', 'G']\n",
      "pairs: Counter({(116, 104): 2, (104, 101): 2, (101, 71): 2, (71, 102): 2, (101, 100): 2, (102, 111): 1, (111, 120): 1, (120, 71): 1, (71, 106): 1, (106, 117): 1, (117, 109): 1, (109, 112): 1, (112, 101): 1, (100, 71): 1, (71, 111): 1, (111, 118): 1, (118, 101): 1, (101, 114): 1, (114, 71): 1, (71, 116): 1, (102, 101): 1, (101, 110): 1, (110, 99): 1, (99, 101): 1})\n",
      "pair_ids: (116, 104)\n"
     ]
    }
   ],
   "source": [
    "mpbe = MyBpe()\n",
    "mpbe.train(\"the fox jumped over the fenced\", 258)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7db0eab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
